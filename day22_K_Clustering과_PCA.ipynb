{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datajcthemax/playdata/blob/main/day22_K_Clustering%EA%B3%BC_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 22번째 이야기\n",
        "- K-Clustering과 PCA\n",
        "- about 준지도학습\n",
        "- TabNet\n",
        "- 머신러닝 시작부터 끝까지 질의응답 미팅"
      ],
      "metadata": {
        "id": "t1mUpbNMp_oc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf10djNjp0tZ",
        "outputId": "fd7854c1-034e-43de-d7d9-799a3c782383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>1.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.10.1)\n",
            "Collecting torch<2.0,>=1.2\n",
            "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.22.4)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (4.65.0)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.9/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.5.0)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch-tabnet) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0,>=1.2->pytorch-tabnet) (67.7.1)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, pytorch-tabnet\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.15.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pytorch-tabnet-4.0 torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xdXgG8U4AKME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlRECxAtASDT",
        "outputId": "de6a5252-1095-4f31-b31b-c9ad768dc158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nmgL5KlvAWJs",
        "outputId": "78aa52eb-b97c-4b51-cc34-6d8bd9f37926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1+cu117'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe6PJFLfAZi6",
        "outputId": "ec766561-3a8a-4bda-a9d7-ce4c49156d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 25 01:23:35 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "PATH = '/content/drive/MyDrive/datas/따릉이/train.csv'\n",
        "data = pd.read_csv(PATH)"
      ],
      "metadata": {
        "id": "e1OwcwxnAkHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "ndL2QvOEBcdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytYH8NQQGHFb",
        "outputId": "dec0077f-723e-42ea-9920-3f0c092c2f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1328 entries, 0 to 1458\n",
            "Data columns (total 11 columns):\n",
            " #   Column                  Non-Null Count  Dtype  \n",
            "---  ------                  --------------  -----  \n",
            " 0   id                      1328 non-null   int64  \n",
            " 1   hour                    1328 non-null   int64  \n",
            " 2   hour_bef_temperature    1328 non-null   float64\n",
            " 3   hour_bef_precipitation  1328 non-null   float64\n",
            " 4   hour_bef_windspeed      1328 non-null   float64\n",
            " 5   hour_bef_humidity       1328 non-null   float64\n",
            " 6   hour_bef_visibility     1328 non-null   float64\n",
            " 7   hour_bef_ozone          1328 non-null   float64\n",
            " 8   hour_bef_pm10           1328 non-null   float64\n",
            " 9   hour_bef_pm2.5          1328 non-null   float64\n",
            " 10  count                   1328 non-null   float64\n",
            "dtypes: float64(9), int64(2)\n",
            "memory usage: 124.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.pop('count')\n",
        "X = data"
      ],
      "metadata": {
        "id": "rkSFZoHmBjAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Br4GW-jALWK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "j_5U87g1BuwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = X_train, X_test, y_train.to_numpy(), y_test.to_numpy()"
      ],
      "metadata": {
        "id": "jhWUQptaCKJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQZiUM-hCVAQ",
        "outputId": "6f8c62c8-c701-4696-cd6b-70ad4dd33c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "# TabNetPretrainer\n",
        "unsupervised_model = TabNetPretrainer(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=1e-3),\n",
        "    mask_type='entmax', # \"sparsemax\"\n",
        ")\n",
        "\n",
        "unsupervised_model.fit(\n",
        "    X_train=X_train,\n",
        "    eval_set=[X_test],\n",
        "    pretraining_ratio=0.8,\n",
        "    batch_size=16\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAVteCPiCGhP",
        "outputId": "bbf041af-6b71-4872-d141-eebd2f52cd1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 80.40638| val_0_unsup_loss_numpy: 8.55443000793457|  0:00:02s\n",
            "epoch 1  | loss: 54.03213| val_0_unsup_loss_numpy: 9.613380432128906|  0:00:05s\n",
            "epoch 2  | loss: 36.08475| val_0_unsup_loss_numpy: 8.623820304870605|  0:00:07s\n",
            "epoch 3  | loss: 24.59331| val_0_unsup_loss_numpy: 8.043729782104492|  0:00:09s\n",
            "epoch 4  | loss: 15.23244| val_0_unsup_loss_numpy: 9.765270233154297|  0:00:11s\n",
            "epoch 5  | loss: 11.61294| val_0_unsup_loss_numpy: 8.98369026184082|  0:00:13s\n",
            "epoch 6  | loss: 8.81305 | val_0_unsup_loss_numpy: 5.680079936981201|  0:00:15s\n",
            "epoch 7  | loss: 6.34877 | val_0_unsup_loss_numpy: 5.152190208435059|  0:00:18s\n",
            "epoch 8  | loss: 4.32741 | val_0_unsup_loss_numpy: 4.222350120544434|  0:00:21s\n",
            "epoch 9  | loss: 3.03826 | val_0_unsup_loss_numpy: 3.0964999198913574|  0:00:23s\n",
            "epoch 10 | loss: 2.27803 | val_0_unsup_loss_numpy: 3.141239881515503|  0:00:25s\n",
            "epoch 11 | loss: 2.18571 | val_0_unsup_loss_numpy: 2.592360019683838|  0:00:27s\n",
            "epoch 12 | loss: 1.56009 | val_0_unsup_loss_numpy: 2.435960054397583|  0:00:29s\n",
            "epoch 13 | loss: 1.62341 | val_0_unsup_loss_numpy: 2.3127100467681885|  0:00:31s\n",
            "epoch 14 | loss: 1.347   | val_0_unsup_loss_numpy: 1.7196199893951416|  0:00:34s\n",
            "epoch 15 | loss: 1.28811 | val_0_unsup_loss_numpy: 1.7713199853897095|  0:00:36s\n",
            "epoch 16 | loss: 1.19027 | val_0_unsup_loss_numpy: 1.4373400211334229|  0:00:38s\n",
            "epoch 17 | loss: 1.20791 | val_0_unsup_loss_numpy: 1.5365500450134277|  0:00:40s\n",
            "epoch 18 | loss: 1.23161 | val_0_unsup_loss_numpy: 1.4782700538635254|  0:00:42s\n",
            "epoch 19 | loss: 1.06796 | val_0_unsup_loss_numpy: 1.3447599411010742|  0:00:45s\n",
            "epoch 20 | loss: 1.04026 | val_0_unsup_loss_numpy: 1.4065200090408325|  0:00:47s\n",
            "epoch 21 | loss: 1.11261 | val_0_unsup_loss_numpy: 1.2702200412750244|  0:00:50s\n",
            "epoch 22 | loss: 1.04846 | val_0_unsup_loss_numpy: 1.260010004043579|  0:00:52s\n",
            "epoch 23 | loss: 1.07239 | val_0_unsup_loss_numpy: 1.219980001449585|  0:00:54s\n",
            "epoch 24 | loss: 1.02408 | val_0_unsup_loss_numpy: 1.1585400104522705|  0:00:56s\n",
            "epoch 25 | loss: 1.01767 | val_0_unsup_loss_numpy: 1.132140040397644|  0:00:58s\n",
            "epoch 26 | loss: 1.06684 | val_0_unsup_loss_numpy: 1.1250100135803223|  0:01:00s\n",
            "epoch 27 | loss: 1.02147 | val_0_unsup_loss_numpy: 1.114609956741333|  0:01:03s\n",
            "epoch 28 | loss: 1.02988 | val_0_unsup_loss_numpy: 1.0917099714279175|  0:01:06s\n",
            "epoch 29 | loss: 1.04193 | val_0_unsup_loss_numpy: 1.1154099702835083|  0:01:08s\n",
            "epoch 30 | loss: 1.03339 | val_0_unsup_loss_numpy: 1.1060099601745605|  0:01:10s\n",
            "epoch 31 | loss: 1.02991 | val_0_unsup_loss_numpy: 1.0759700536727905|  0:01:12s\n",
            "epoch 32 | loss: 0.99874 | val_0_unsup_loss_numpy: 1.079450011253357|  0:01:14s\n",
            "epoch 33 | loss: 0.97609 | val_0_unsup_loss_numpy: 1.0581300258636475|  0:01:16s\n",
            "epoch 34 | loss: 1.00749 | val_0_unsup_loss_numpy: 1.0671800374984741|  0:01:19s\n",
            "epoch 35 | loss: 0.96161 | val_0_unsup_loss_numpy: 1.0712599754333496|  0:01:21s\n",
            "epoch 36 | loss: 0.99785 | val_0_unsup_loss_numpy: 1.1714400053024292|  0:01:23s\n",
            "epoch 37 | loss: 0.9741  | val_0_unsup_loss_numpy: 1.20346999168396|  0:01:25s\n",
            "epoch 38 | loss: 0.95606 | val_0_unsup_loss_numpy: 1.1648600101470947|  0:01:27s\n",
            "epoch 39 | loss: 0.97047 | val_0_unsup_loss_numpy: 1.1722500324249268|  0:01:29s\n",
            "epoch 40 | loss: 0.95347 | val_0_unsup_loss_numpy: 1.119439959526062|  0:01:32s\n",
            "epoch 41 | loss: 0.98353 | val_0_unsup_loss_numpy: 1.064579963684082|  0:01:34s\n",
            "epoch 42 | loss: 0.95769 | val_0_unsup_loss_numpy: 1.0963799953460693|  0:01:36s\n",
            "epoch 43 | loss: 0.98561 | val_0_unsup_loss_numpy: 1.0789799690246582|  0:01:38s\n",
            "\n",
            "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_unsup_loss_numpy = 1.0581300258636475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetRegressor\n",
        "\n",
        "clf = TabNetRegressor(\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=1e-3),\n",
        "    scheduler_params={\"step_size\":10, # how to use learning rate scheduler\n",
        "                      \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax' # This will be overwritten if using pretrain model\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train.reshape(-1,1),\n",
        "    eval_set=[(X_train, y_train.reshape(-1,1)), (X_test, y_test.reshape(-1,1))],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['rmse'],\n",
        "    from_unsupervised=unsupervised_model,batch_size=8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfgrAqh6DyzZ",
        "outputId": "9c7606e7-8884-4de8-8643-a6ed88105758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:105: UserWarning: Pretraining: mask_type changed from sparsemax to entmax\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.9/dist-packages/pytorch_tabnet/abstract_model.py:231: UserWarning: Loading weights from unsupervised pretraining\n",
            "  warnings.warn(\"Loading weights from unsupervised pretraining\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 18801.74652| train_rmse: 137.17806| valid_rmse: 132.45109|  0:00:04s\n",
            "epoch 1  | loss: 18260.55694| train_rmse: 134.48133| valid_rmse: 130.22859|  0:00:08s\n",
            "epoch 2  | loss: 17220.00829| train_rmse: 130.88515| valid_rmse: 126.96969|  0:00:14s\n",
            "epoch 3  | loss: 15856.55357| train_rmse: 124.90751| valid_rmse: 121.20262|  0:00:18s\n",
            "epoch 4  | loss: 14258.08502| train_rmse: 116.97406| valid_rmse: 113.73529|  0:00:22s\n",
            "epoch 5  | loss: 12381.29668| train_rmse: 108.27731| valid_rmse: 104.89527|  0:00:27s\n",
            "epoch 6  | loss: 10620.5443| train_rmse: 99.16713| valid_rmse: 96.04575|  0:00:32s\n",
            "epoch 7  | loss: 8848.18018| train_rmse: 90.63128| valid_rmse: 87.43726|  0:00:36s\n",
            "epoch 8  | loss: 7250.82282| train_rmse: 82.03851| valid_rmse: 79.47069|  0:00:41s\n",
            "epoch 9  | loss: 6236.39324| train_rmse: 75.02666| valid_rmse: 72.84199|  0:00:46s\n",
            "epoch 10 | loss: 5406.44365| train_rmse: 69.69316| valid_rmse: 67.36945|  0:00:50s\n",
            "epoch 11 | loss: 4987.39691| train_rmse: 65.49371| valid_rmse: 63.28254|  0:00:55s\n",
            "epoch 12 | loss: 4394.77294| train_rmse: 61.81032| valid_rmse: 59.89809|  0:01:00s\n",
            "epoch 13 | loss: 4100.35058| train_rmse: 59.17423| valid_rmse: 57.79626|  0:01:05s\n",
            "epoch 14 | loss: 3856.61853| train_rmse: 57.47287| valid_rmse: 56.10368|  0:01:09s\n",
            "epoch 15 | loss: 3792.2314| train_rmse: 56.31706| valid_rmse: 54.65447|  0:01:14s\n",
            "epoch 16 | loss: 3737.06897| train_rmse: 54.76684| valid_rmse: 53.48536|  0:01:19s\n",
            "epoch 17 | loss: 3653.41166| train_rmse: 56.09847| valid_rmse: 54.11093|  0:01:23s\n",
            "epoch 18 | loss: 3452.64944| train_rmse: 54.47836| valid_rmse: 52.48765|  0:01:29s\n",
            "epoch 19 | loss: 3535.15211| train_rmse: 53.43173| valid_rmse: 51.6435 |  0:01:33s\n",
            "epoch 20 | loss: 3460.20923| train_rmse: 52.54978| valid_rmse: 51.14228|  0:01:37s\n",
            "epoch 21 | loss: 3379.49077| train_rmse: 53.63496| valid_rmse: 51.56052|  0:01:43s\n",
            "epoch 22 | loss: 3185.45621| train_rmse: 52.22806| valid_rmse: 50.84323|  0:01:47s\n",
            "epoch 23 | loss: 3127.23804| train_rmse: 51.98573| valid_rmse: 50.61114|  0:01:51s\n",
            "epoch 24 | loss: 3234.53948| train_rmse: 53.54947| valid_rmse: 51.68809|  0:01:57s\n",
            "epoch 25 | loss: 3538.36279| train_rmse: 53.36051| valid_rmse: 51.30439|  0:02:01s\n",
            "epoch 26 | loss: 3245.14024| train_rmse: 52.58747| valid_rmse: 50.87279|  0:02:06s\n",
            "epoch 27 | loss: 3252.81695| train_rmse: 52.90562| valid_rmse: 50.94086|  0:02:11s\n",
            "epoch 28 | loss: 3610.32402| train_rmse: 53.4183 | valid_rmse: 51.75007|  0:02:15s\n",
            "epoch 29 | loss: 3290.9339| train_rmse: 52.40757| valid_rmse: 50.80093|  0:02:20s\n",
            "epoch 30 | loss: 3221.34204| train_rmse: 51.12579| valid_rmse: 49.91233|  0:02:25s\n",
            "epoch 31 | loss: 3242.39265| train_rmse: 52.25767| valid_rmse: 50.39677|  0:02:30s\n",
            "epoch 32 | loss: 3131.90188| train_rmse: 51.85487| valid_rmse: 50.24932|  0:02:34s\n",
            "epoch 33 | loss: 3177.51127| train_rmse: 51.57129| valid_rmse: 50.01257|  0:02:39s\n",
            "epoch 34 | loss: 3192.23575| train_rmse: 52.06397| valid_rmse: 50.7604 |  0:02:44s\n",
            "epoch 35 | loss: 3100.81723| train_rmse: 51.56363| valid_rmse: 49.85309|  0:02:48s\n",
            "epoch 36 | loss: 3215.95962| train_rmse: 52.2368 | valid_rmse: 50.21226|  0:02:53s\n",
            "epoch 37 | loss: 3089.71195| train_rmse: 50.82804| valid_rmse: 49.37473|  0:02:58s\n",
            "epoch 38 | loss: 2935.5975| train_rmse: 51.17605| valid_rmse: 49.48991|  0:03:02s\n",
            "epoch 39 | loss: 3186.32415| train_rmse: 51.07259| valid_rmse: 49.43983|  0:03:07s\n",
            "epoch 40 | loss: 3249.26983| train_rmse: 51.0445 | valid_rmse: 49.6773 |  0:03:12s\n",
            "epoch 41 | loss: 3175.35258| train_rmse: 51.33585| valid_rmse: 49.75435|  0:03:16s\n",
            "epoch 42 | loss: 3318.62288| train_rmse: 51.16403| valid_rmse: 49.63214|  0:03:21s\n",
            "epoch 43 | loss: 2973.7659| train_rmse: 50.53292| valid_rmse: 49.3946 |  0:03:26s\n",
            "epoch 44 | loss: 3021.8769| train_rmse: 50.29425| valid_rmse: 49.00337|  0:03:30s\n",
            "epoch 45 | loss: 2955.2492| train_rmse: 51.18429| valid_rmse: 49.6979 |  0:03:35s\n",
            "epoch 46 | loss: 2967.46482| train_rmse: 51.33489| valid_rmse: 49.59136|  0:03:40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "7MBq0vOvKMl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test, pred)"
      ],
      "metadata": {
        "id": "I0stHw6jOyoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}